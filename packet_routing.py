from xuance.environment import RawMultiAgentEnv
from collections import deque
import numpy as np
import random
from gymnasium.spaces import Box, Discrete
import networkx as nx
import os
import csv
from xuance.environment.multi_agent_env.satellite_network import create_satellite_network  # å¯¼å…¥å¤–éƒ¨å‡½æ•°
import time


class Packet:
    def __init__(self, source, destination):
        self.source = source
        self.destination = destination
        self.hops = 0
        self.nodes = [source]
        self.actions = []
        self.rewards = []
        self.visited_nodes = set()  # å·²è®¿é—®èŠ‚ç‚¹çš„é›†åˆ
        self.visited_nodes.add(source)  # åˆå§‹åŒ–æ—¶å°†æºèŠ‚ç‚¹åŠ å…¥é›†åˆ
        self.arrival_time = None  # åˆ°è¾¾ç›®çš„èŠ‚ç‚¹çš„æ—¶é—´
        self.transmission_delays = []  # ä¼ è¾“æ—¶å»¶è®°å½•
        self.propagation_delays = []  # ä¼ æ’­æ—¶å»¶è®°å½•
        self.queue_delays = []  # æ’é˜Ÿæ—¶å»¶è®°å½•
        self.enqueue_time = None  # è¿›å…¥é˜Ÿåˆ—çš„æ—¶é—´æ­¥
        self.queue_delay_steps = 0  # ç´¯è®¡æ’é˜Ÿçš„æ­¥æ•°
        self.packet_id = None
        self.path_delays = []
        self.total_delay = 0
        self.start_time = time.time()
        self.max_hops = 0  # æœ€å¤§è·³æ•°
        self.is_dropped = False  # ä¸¢åŒ…æ ‡å¿—
        self.drop_reason = None  # ä¸¢åŒ…åŸå› 

    def add_hop(self, next_node, delay):
        self.nodes.append(next_node)
        self.visited_nodes.add(next_node)
        self.path_delays.append(delay)
        self.total_delay += delay
        self.hops += 1

    def print_path_info(self):
        print(f"\næ•°æ®åŒ… {self.packet_id} çš„ä¼ è¾“ä¿¡æ¯:")
        print(f"è½¬å‘è·¯å¾„: {' -> '.join(map(str, self.nodes))}")
        print(f"è·³æ•°: {self.hops}")
        print(f"æ¯è·³å»¶è¿Ÿ (ms): {[f'{delay:.2f}' for delay in self.path_delays]}")
        print(f"æ€»å»¶è¿Ÿ (ms): {self.total_delay:.2f}")
        print(f"å·²è®¿é—®èŠ‚ç‚¹: {sorted(list(self.visited_nodes))}")
        if self.arrival_time:
            transmission_time = self.arrival_time - self.start_time
            print(f"ä¼ è¾“æ€»æ—¶é—´: {transmission_time:.2f}ç§’")


class PacketRoutingEnv(RawMultiAgentEnv):
    def __init__(self, config=None):
        super().__init__()

        # ä» config ä¸­æå–å‚æ•°
        self.max_episode_steps = getattr(config, 'max_steps', 150)
        self.seed = getattr(config, 'seed', 64)
        self.common_reward = getattr(config, 'common_reward', False)
        self.reward_scalarisation = getattr(config, 'reward_scalarisation', "mean")
        self.algorithm = getattr(config, 'algorithm', 'mappo')
        self.enable_topology_clipping = getattr(config, 'enable_topology_clipping', True)

        # å¥–åŠ±å’Œæƒ©ç½šå‚æ•°é…ç½®
        self.rewards_config = {
            # âœ… 1. ç»´æŒåŸºç¡€å¥–åŠ±
            'step_penalty': -1,

            # âœ… 2. æé«˜å¥–åŠ±ï¼Œè®©æ™ºèƒ½ä½“æ›´ç§¯æå¯»æ±‚å…¨å±€æœ€ä¼˜
            'packet_arrival_reward': 100,  # æé«˜å•ä¸ªæ•°æ®åŒ…åˆ°è¾¾å¥–åŠ±
            'path_completion_reward': 2000,

            # âœ… 3. å¼ºåŒ–è·¯å¾„ä¼˜åŒ–ç­–ç•¥
            'distance_reward_weight': 50,  # å¢åŠ å‘ç›®æ ‡ç§»åŠ¨çš„å¥–åŠ±æƒé‡
            'distance_penalty_weight': -25,  # ç›¸åº”è°ƒæ•´æƒ©ç½šæƒé‡

            # âœ… 4. æé«˜é”™è¯¯å†³ç­–æƒ©ç½š
            'loop_penalty': -30,  # å¢åŠ å¾ªç¯æƒ©ç½š
            'queue_full_penalty': -15,
            'drop_penalty': -10,
            'wrong_destination_penalty': -20,
            'max_hops_penalty': -20,

            # âœ… 5. åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘å¥–åŠ±ï¼ˆæŒ‡æ•°å¢é•¿ï¼‰
            'arrival_20_reward': 200,     # 20%æ•°æ®åŒ…åˆ°è¾¾
            'arrival_40_reward': 400,     # 40%æ•°æ®åŒ…åˆ°è¾¾
            'arrival_60_reward': 800,     # 60%æ•°æ®åŒ…åˆ°è¾¾
            'arrival_80_reward': 1600,    # 80%æ•°æ®åŒ…åˆ°è¾¾
            'arrival_100_reward': 3200,   # 100%æ•°æ®åŒ…åˆ°è¾¾
        }

        # åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘è®¾ç½®
        self.arrival_milestones = {
            0.20: 'arrival_20_reward',   # 20%
            0.40: 'arrival_40_reward',   # 40%
            0.60: 'arrival_60_reward',   # 60%
            0.80: 'arrival_80_reward',   # 80%
            1.00: 'arrival_100_reward',  # 100%
        }
        
        # æ·»åŠ åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘è¿½è¸ª
        self.reached_arrival_milestones = set()

        # å«æ˜Ÿç½‘ç»œæ‹“æ‰‘å‚æ•°
        self.number_of_orbital_planes = getattr(config, 'number_of_orbital_planes', 4)
        self.number_of_satellites_per_plane = getattr(config, 'number_of_satellites_per_plane', 43)
        self.satellite_height = getattr(config, 'satellite_height', 560)

        # å…¨å±€è®¡æ•°å™¨
        self.global_episode_count = 0
        self.episode_done = False

        # å¸¦å®½è®¾ç½®
        self.bandwidth = getattr(config, 'bandwidth', 10e9)
        self.packet_size = 1500 * 8
        self.bandwidth_in_packets_per_sec = self.bandwidth / self.packet_size

        # å›¾å½¢å’Œç½‘ç»œåˆå§‹åŒ–
        self.graph, self.source_node, self.destination_node = self.create_graph()
        self.current_step = 0

        # è®¡ç®—æœ€çŸ­è·¯å¾„å’Œæœ€å¤§è·³æ•°
        shortest_path = nx.shortest_path(self.graph, self.source_node, self.destination_node)
        self.shortest_path_length = len(shortest_path) - 1  # å‡1æ˜¯å› ä¸ºè·¯å¾„é•¿åº¦åŒ…å«äº†èµ·å§‹èŠ‚ç‚¹
        self.max_hops = self.shortest_path_length * 2  # è®¾ç½®æœ€å¤§è·³æ•°ä¸ºæœ€çŸ­è·¯å¾„é•¿åº¦çš„2å€
        print(f"æœ€å¤§å…è®¸è·³æ•°: {self.max_hops}")

        # æ•°æ®åŒ…å‚æ•°
        self.packets = getattr(config, 'packets', 50)
        self.received_packets_count = 0
        self.packet_sequence_number = 1

        # é˜Ÿåˆ—å®¹é‡å’Œç»“æ„
        self.queue_capacity = getattr(config, 'queue_capacity', 10)
        self.queues = {
            node: deque(maxlen=self.packets) if node in [self.source_node, self.destination_node] else deque(
                maxlen=self.queue_capacity)
            for node in self.graph.nodes()
        }

        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹åˆ°ç›®çš„èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦
        self.shortest_paths = nx.single_source_shortest_path_length(self.graph, self.destination_node)
        self.neighbours = {node: list(self.graph.neighbors(node)) for node in self.graph.nodes()}

        self.agents = [f"agent_{node}" for node in sorted(self.graph.nodes())]
        self.possible_agents = self.agents[:]
        self.num_agents = len(self.agents)
        self.agent_groups = [self.agents]

        max_neighbors = max(len(neighbors) for neighbors in self.neighbours.values())
        obs_space_size = 1 + max_neighbors * 3 + 1
        self.observation_space = {
            agent: Box(
                low=np.zeros(obs_space_size, dtype=np.float32),
                high=np.ones(obs_space_size, dtype=np.float32) * np.float32(np.inf),
                shape=(obs_space_size,),
                dtype=np.float32
            ) for agent in self.agents
        }

        # ä¿®æ”¹åŠ¨ä½œç©ºé—´ä¸ºä¸€ç»´ï¼Œåªéœ€è¦é€‰æ‹©é‚»å±…èŠ‚ç‚¹
        self.action_space = {
            agent: Box(
                low=np.zeros(1, dtype=np.float32),
                high=np.ones(1, dtype=np.float32),
                shape=(1,),
                dtype=np.float32
            ) for agent in self.agents
        }

        self.state_space = Box(
            low=np.zeros(obs_space_size * len(self.agents), dtype=np.float32),  # æ˜ç¡®æŒ‡å®š dtype
            high=np.ones(obs_space_size * len(self.agents), dtype=np.float32) * np.float32(np.inf),  # æ˜ç¡®æŒ‡å®š dtype
            shape=(obs_space_size * len(self.agents),),
            dtype=np.float32
        )

        # å¥–åŠ±å‚æ•°åˆå§‹åŒ–
        self.best_total_delay = float('inf')
        self.best_reward = float('-inf')

        # å¥–åŠ±å‚æ•°è°ƒæ•´
        self.distance_reward_weight = getattr(config, 'distance_reward_weight', 100)  # å¢åŠ å‘ç›®æ ‡ç§»åŠ¨çš„å¥–åŠ±
        self.distance_penalty_weight = getattr(config, 'distance_penalty_weight', -100)  # åŠ å¤§è¿œç¦»ç›®æ ‡çš„æƒ©ç½š
        self.loop_penalty = getattr(config, 'loop_penalty', -50)  # åŠ å¤§å¾ªç¯è·¯å¾„çš„æƒ©ç½š
        self.packet_arrival_reward = getattr(config, 'packet_arrival_reward', 200)  # å•ä¸ªæ•°æ®åŒ…åˆ°è¾¾çš„å¥–åŠ±
        self.path_completion_reward = getattr(config, 'path_completion_reward', 1000)  # æ‰€æœ‰æ•°æ®åŒ…éƒ½åˆ°è¾¾çš„å¥–åŠ±

        # ç»Ÿè®¡ç›¸å…³å‚æ•°
        self.episode_count = 0
        self.final_rewards_history = []
        self.last_packet_arrival_time = None

        # ä¿®æ”¹æ–‡ä»¶è·¯å¾„
        base_path = os.path.dirname(__file__)
        self.csv_file = os.path.join(base_path, f'results_{self.algorithm}.csv')
        self.plot_file = os.path.join(base_path, f'rewards_plot_{self.algorithm}.html')

        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self.initialize_csv()

        # é‡ç½®ç¯å¢ƒ
        self.episode_total_reward = 0.0  # å½“å‰å›åˆçš„æ€»å¥–åŠ±
        self.episode_agent_rewards = {agent: 0.0 for agent in self.agents}  # æ¯ä¸ªæ™ºèƒ½ä½“çš„å›åˆå¥–åŠ±

        # æ·»åŠ æ•°æ®åŒ…è·Ÿè¸ª
        self.all_packets = {}  # ç”¨äºè·Ÿè¸ªæ‰€æœ‰æ•°æ®åŒ…
        self.current_episode_packets = set()  # å½“å‰å›åˆçš„æ•°æ®åŒ…IDé›†åˆ

        # æ·»åŠ è®¡æ•°å™¨
        self.dropped_packets_count = 0  # å› è¶…è¿‡è·³æ•°é™åˆ¶è€Œä¸¢å¼ƒçš„æ•°æ®åŒ…æ•°é‡

        self.reset()

    def reset(self, **kwargs):
        # é‡ç½®æ•°æ®åŒ…è·Ÿè¸ª
        self.all_packets = {}
        self.current_episode_packets = set()
        self.packet_sequence_number = 1

        # æ›´æ–°å…¨å±€å›åˆå’Œæ­¥æ•°è®¡æ•°å™¨
        self.current_step = 0
        self.received_packets_count = 0
        self.episode_done = False

        # åˆå§‹åŒ–ä¸ªä½“å›åˆå¥–åŠ±å­—å…¸
        self.individual_episode_reward = {agent: 0.0 for agent in self.agents}

        # è®¾ç½®éšæœºç§å­
        seed = kwargs.get("seed", None)
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        # åˆå§‹åŒ–å¥–åŠ±ã€ç»ˆæ­¢æ ‡å¿—ã€æˆªæ–­æ ‡å¿—å’Œé¢å¤–ä¿¡æ¯
        self.rewards = {agent: 0 for agent in self.agents}
        self.terminations = {agent: False for agent in self.agents}
        self.truncations = {agent: False for agent in self.agents}
        self.infos = {agent: {} for agent in self.agents}

        # åˆå§‹åŒ–é˜Ÿåˆ—çŠ¶æ€
        self.queues = {
            node: deque(maxlen=self.packets) if node in [self.source_node, self.destination_node] else deque(
                maxlen=self.queue_capacity)
            for node in self.graph.nodes()
        }

        # åˆå§‹åŒ–é€šé“çŠ¶æ€
        self.channels = {
            node: {neighbour: deque() for neighbour in self.neighbours[node]}
            for node in self.graph.nodes()
        }

        # åœ¨æºèŠ‚ç‚¹ç”Ÿæˆæ•°æ®åŒ…
        self.generate_packets(num_packets=self.packets)

        # åˆ›å»ºæ¯ä¸ªä»£ç†çš„åˆå§‹è§‚æµ‹å€¼
        self.observations = {agent: self.observe(agent) for agent in self.agents}
        self.dones = {agent: False for agent in self.agents}

        # é‡ç½®å›åˆæ€»å¥–åŠ±
        self.episode_total_reward = 0.0
        self.episode_agent_rewards = {agent: 0.0 for agent in self.agents}

        # é‡ç½®è®¡æ•°å™¨
        self.dropped_packets_count = 0

        # é‡ç½®åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘
        self.reached_arrival_milestones = set()

        # è¿”å›åˆå§‹è§‚æµ‹å€¼å’Œç¯å¢ƒä¿¡æ¯
        return self.observations, self.infos

    def step(self, action_dict):
        """æ‰§è¡Œç¯å¢ƒçš„ä¸€æ­¥"""
        self.current_step += 1
        observations = {}
        rewards = {agent: 0 for agent in self.agents}
        terminations = {}
        infos = {agent: {} for agent in self.agents}

        # print(f"\n=== Step {self.current_step} ===")

        # **æ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œ**
        for agent_id, action in action_dict.items():
            if self.terminations[agent_id]:
                continue
            node = int(agent_id.split('_')[1])
            packet_reached_destination = self.perform_action(node, action)
            rewards[agent_id] += self.rewards[agent_id]
            # ç´¯åŠ æ¯ä¸ªæ™ºèƒ½ä½“çš„å›åˆå¥–åŠ±
            self.episode_agent_rewards[agent_id] += rewards[agent_id]

        # **æ‰§è¡Œæ•°æ®åŒ…è½¬ç§»**
        self.transfer_packets()

        # **æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€**
        queue_lengths = {node: len(self.queues[node]) for node in self.graph.nodes() if len(self.queues[node]) > 0}

        # **æ£€æŸ¥åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘**
        self.check_arrival_milestones()

        # **æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ•°æ®åŒ…éƒ½å·²å¤„ç†å®Œæ¯•ï¼ˆåˆ°è¾¾ç›®çš„åœ°æˆ–è¢«ä¸¢å¼ƒï¼‰**
        total_processed_packets = self.received_packets_count + self.dropped_packets_count
        if total_processed_packets == self.packets:
            success_rate = (self.received_packets_count / self.packets) * 100
            print(f"\nâœ… æ‰€æœ‰æ•°æ®åŒ…å¤„ç†å®Œæ¯•ï¼")
            print(f"æˆåŠŸåˆ°è¾¾: {self.received_packets_count} ({success_rate:.1f}%)")
            print(f"å› è·³æ•°é™åˆ¶ä¸¢å¼ƒ: {self.dropped_packets_count} ({100-success_rate:.1f}%)")
            print(f"æ€»å…±ç”¨äº† {self.current_step} æ­¥")
            
            for agent_id in self.agents:
                self.terminations[agent_id] = True

        # **æ›´æ–°è§‚æµ‹**
        for agent_id in self.agents:
            observations[agent_id] = self.observe(agent_id)
            terminations[agent_id] = self.terminations[agent_id]

        # **ç´¯åŠ å½“å‰æ­¥éª¤æ‰€æœ‰æ™ºèƒ½ä½“çš„å¥–åŠ±**
        step_total_reward = sum(rewards.values())
        self.episode_total_reward += step_total_reward

        # **è¾¾åˆ°æœ€å¤§æ­¥æ•°æ—¶ç»ˆæ­¢**
        truncated = self.current_step >= self.max_episode_steps

        # ä¿®æ”¹å›åˆç»“æŸçš„æ¡ä»¶ï¼šæ‰€æœ‰æ™ºèƒ½ä½“éƒ½ç»ˆæ­¢æˆ–è¾¾åˆ°æœ€å¤§æ­¥æ•°æˆ–æ‰€æœ‰æ•°æ®åŒ…éƒ½å·²å¤„ç†å®Œæ¯•
        episode_done = all(terminations.values()) or truncated or total_processed_packets == self.packets

        if episode_done:
            self.global_episode_count += 1
            self.log_rewards_to_csv(self.global_episode_count, self.episode_total_reward)
            self.print_episode_summary()

        return observations, rewards, terminations, truncated, infos

    def state(self):
        """è¿”å›ç¯å¢ƒçš„å…¨å±€çŠ¶æ€"""
        try:
            # è·å–æ‰€æœ‰æ™ºèƒ½ä½“çš„è§‚æµ‹å€¼å¹¶æ‹¼æ¥
            state = np.concatenate([self.observe(agent) for agent in self.agents])
            return state
        except Exception as e:
            raise RuntimeError(f"Error in getting state: {e}")

    def agent_mask(self):
        """è¿”å›æ™ºèƒ½ä½“çš„æœ‰æ•ˆæ€§æ©ç """
        return {agent: not self.terminations[agent] for agent in self.agents}

    def avail_actions(self):
        """è¿”å›æ¯ä¸ªæ™ºèƒ½ä½“å¯ç”¨åŠ¨ä½œçš„æ©ç """
        avail_actions = {}
        for agent in self.agents:
            node = int(agent.split('_')[1])
            num_neighbors = len(self.neighbours[node])
            # å¯¹äºè¿ç»­åŠ¨ä½œç©ºé—´ï¼Œè¿”å›True
            avail_actions[agent] = np.ones(self.action_space[agent].shape, dtype=np.bool_)
        return avail_actions

    def render(self, mode="human"):
        """æ¸²æŸ“ç¯å¢ƒ"""
        pass

    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass

    def initialize_csv(self):
        """åˆå§‹åŒ– CSV æ–‡ä»¶ï¼Œå†™å…¥è¡¨å¤´"""
        if not os.path.exists(self.csv_file):
            with open(self.csv_file, mode='w', newline='') as file:
                writer = csv.writer(file)
                writer.writerow(["Episode", "Total Reward"])

    def log_rewards_to_csv(self, episode, total_reward):
        """å°†æ¯å›åˆçš„å¥–åŠ±æ€»å’Œè®°å½•åˆ° CSV æ–‡ä»¶"""
        with open(self.csv_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([episode, total_reward])

    def create_graph(self):
        return create_satellite_network(self)

    def generate_packets(self, num_packets=None):
        """ç”Ÿæˆæ•°æ®åŒ…"""
        if num_packets is None:
            num_packets = self.packets

        for i in range(num_packets):
            packet = Packet(self.source_node, self.destination_node)  # ä½¿ç”¨self.destination_nodeä½œä¸ºç›®çš„èŠ‚ç‚¹
            packet.packet_id = f"P{self.packet_sequence_number}"
            # ä½¿ç”¨ç±»çº§åˆ«çš„æœ€å¤§è·³æ•°
            packet.max_hops = self.max_hops
            self.packet_sequence_number += 1
            self.queues[self.source_node].append(packet)
            self.all_packets[packet.packet_id] = packet
            self.current_episode_packets.add(packet.packet_id)

    def transfer_packets(self):
        """ä»é€šé“ä¸­ç§»åŠ¨æ•°æ®åŒ…åˆ°ç›®æ ‡èŠ‚ç‚¹é˜Ÿåˆ—"""
        # åˆ›å»ºä¸´æ—¶å­—å…¸æ¥å­˜å‚¨éœ€è¦å¤„ç†çš„æ•°æ®åŒ…
        pending_packets = {}

        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ•°æ®åŒ…
        for node in self.channels:
            for neighbour, packets in list(self.channels[node].items()):
                while packets:
                    packet = packets.popleft()
                    if neighbour not in pending_packets:
                        pending_packets[neighbour] = []
                    pending_packets[neighbour].append((node, packet))

        # ç¬¬äºŒæ­¥ï¼šå¤„ç†æ¯ä¸ªèŠ‚ç‚¹çš„æ•°æ®åŒ…
        for target_node, packet_list in pending_packets.items():
            # å¤„ç†æ•°æ®åŒ…
            for source_node, packet in packet_list:
                # å®æ—¶è®¡ç®—ç›®æ ‡èŠ‚ç‚¹çš„å‰©ä½™å®¹é‡
                current_queue_length = len(self.queues[target_node])
                if target_node in [self.source_node, self.destination_node]:
                    remaining_capacity = self.packets - current_queue_length
                else:
                    remaining_capacity = self.queue_capacity - current_queue_length

                if remaining_capacity > 0:
                    self.queues[target_node].append(packet)
                else:
                    # ç›®æ ‡é˜Ÿåˆ—æ»¡æ—¶ï¼Œå°†æ•°æ®åŒ…æ”¾å›åŸèŠ‚ç‚¹
                    if source_node != self.source_node:  # å¦‚æœä¸æ˜¯æºèŠ‚ç‚¹ï¼Œæ‰æ”¾å›åŸèŠ‚ç‚¹
                        self.queues[source_node].append(packet)
                        # å¯¹æ‰€æœ‰å‚ä¸è½¬å‘çš„èŠ‚ç‚¹æ–½åŠ è¾ƒå°çš„æƒ©ç½š
                        for visited_node in packet.visited_nodes:
                            self.rewards[f"agent_{visited_node}"] += self.rewards_config[
                                                                         'queue_full_penalty'] / 2  # å‡å°æƒ©ç½šåŠ›åº¦

        # æ¸…ç©ºæ‰€æœ‰é€šé“
        for node in self.channels:
            for neighbour in self.channels[node]:
                self.channels[node][neighbour].clear()

    def observe(self, agent_id):
        node = int(agent_id.split('_')[1])
        obs_size = self.observation_space[agent_id].shape[0]
        if len(self.queues[node]) > 0:
            packet = self.queues[node][0]
            obs = [packet.destination] + [len(self.queues[n]) for n in self.neighbours[node]]
            obs.extend([self.graph[node][n]['delay'] for n in self.neighbours[node]])
            obs.extend([1 if n in packet.visited_nodes else 0 for n in self.neighbours[node]])
            obs.append(len(self.queues[node]))
        else:
            obs = [0] * (1 + len(self.neighbours[node]) * 3 + 1)

        padded_obs = np.zeros(obs_size, dtype=np.float32)
        padded_obs[:len(obs)] = obs
        return padded_obs

    def perform_action(self, node, action):
        packet_reached_destination = False
        if not self.queues[node]:
            return packet_reached_destination

        num_neighbors = len(self.neighbours[node])
        if num_neighbors == 0:
            return packet_reached_destination

        # åªä½¿ç”¨action[0]æ¥é€‰æ‹©é‚»å±…èŠ‚ç‚¹
        primary_neighbor_idx = min(int(action[0] * num_neighbors), num_neighbors - 1)
        primary_neighbor_idx = max(0, primary_neighbor_idx)
        next_node = self.neighbours[node][primary_neighbor_idx]

        # æ£€æŸ¥é€‰æ‹©çš„èŠ‚ç‚¹æ˜¯å¦é˜Ÿåˆ—å·²æ»¡
        if next_node in [self.source_node, self.destination_node]:
            initial_remaining_capacity = self.packets - len(self.queues[next_node])
        else:
            initial_remaining_capacity = self.queue_capacity - len(self.queues[next_node])

        # å¦‚æœé€‰æ‹©çš„èŠ‚ç‚¹é˜Ÿåˆ—å·²æ»¡
        if initial_remaining_capacity <= 0:
            # ç»™äºˆå½“å‰èŠ‚ç‚¹æƒ©ç½š
            self.rewards[f"agent_{node}"] += self.rewards_config['queue_full_penalty']

            # è·å–æ‰€æœ‰å¯ç”¨çš„é‚»å±…èŠ‚ç‚¹ï¼ˆé˜Ÿåˆ—æœªæ»¡çš„èŠ‚ç‚¹ï¼‰
            available_neighbors = []
            for neighbor in self.neighbours[node]:
                if neighbor in [self.source_node, self.destination_node]:
                    remaining_capacity = self.packets - len(self.queues[neighbor])
                else:
                    remaining_capacity = self.queue_capacity - len(self.queues[neighbor])
                if remaining_capacity > 0:
                    available_neighbors.append(neighbor)

            # å¦‚æœæœ‰å¯ç”¨çš„é‚»å±…èŠ‚ç‚¹ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
            if available_neighbors:
                next_node = np.random.choice(available_neighbors)
                if next_node in [self.source_node, self.destination_node]:
                    remaining_capacity = self.packets - len(self.queues[next_node])
                else:
                    remaining_capacity = self.queue_capacity - len(self.queues[next_node])
            else:
                # å¦‚æœæ‰€æœ‰é‚»å±…èŠ‚ç‚¹éƒ½æ»¡äº†ï¼Œä¿æŒåœ¨åŸèŠ‚ç‚¹
                return packet_reached_destination

        else:
            remaining_capacity = initial_remaining_capacity

        # è®¡ç®—å¯ä»¥è½¬å‘çš„æ•°æ®åŒ…æ•°é‡
        available_packets = len(self.queues[node])
        transfer_count = min(available_packets, remaining_capacity)

        # è½¬å‘æ•°æ®åŒ…
        for _ in range(transfer_count):
            if not self.queues[node]:
                break
            packet = self.queues[node].popleft()

            # æ£€æŸ¥æ˜¯å¦é‡å¤è®¿é—®èŠ‚ç‚¹ï¼Œå¦‚æœæ˜¯åˆ™ç»™äºˆæƒ©ç½š
            if next_node in packet.visited_nodes:
                self.rewards[f"agent_{node}"] += self.rewards_config['loop_penalty']

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è·³æ•°
            if packet.hops >= packet.max_hops:
                packet.is_dropped = True
                packet.drop_reason = "è¶…è¿‡æœ€å¤§è·³æ•°é™åˆ¶"
                self.dropped_packets_count += 1  # å¢åŠ ä¸¢å¼ƒè®¡æ•°
                for visited_node in packet.visited_nodes:
                    self.rewards[f"agent_{visited_node}"] += self.rewards_config['max_hops_penalty']
                continue

            # è®¡ç®—å½“å‰èŠ‚ç‚¹å’Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹åˆ°ç›®çš„èŠ‚ç‚¹çš„è·ç¦»
            current_distance = self.shortest_paths[node]
            next_distance = self.shortest_paths[next_node]

            # è·å–è¾¹çš„å»¶è¿Ÿ
            link_delay = self.graph[node][next_node]['delay']
            packet.add_hop(next_node, link_delay)

            # è®¡ç®—è·ç¦»ç›¸å…³å¥–åŠ±
            if next_distance < current_distance:
                distance_reward = (current_distance - next_distance) * self.rewards_config['distance_reward_weight']
                self.rewards[f"agent_{node}"] += distance_reward
            else:
                distance_penalty = (next_distance - current_distance) * self.rewards_config['distance_penalty_weight']
                self.rewards[f"agent_{node}"] += distance_penalty

            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®çš„åœ°
            if next_node == packet.destination and next_node == self.destination_node:
                packet_reached_destination = True
                self.received_packets_count += 1
                packet.arrival_time = time.time()
                # å¯¹æ‰€æœ‰å‚ä¸è½¬å‘çš„èŠ‚ç‚¹ç»™äºˆå®Œæ•´å¥–åŠ±
                for visited_node in packet.visited_nodes:
                    self.rewards[f"agent_{visited_node}"] += self.rewards_config['packet_arrival_reward']
                continue
            elif next_node != self.destination_node and next_node == packet.destination:
                packet.is_dropped = True
                packet.drop_reason = f"åˆ°è¾¾é”™è¯¯çš„ç›®çš„èŠ‚ç‚¹: {next_node}, åº”è¯¥åˆ°è¾¾: {self.destination_node}"
                for visited_node in packet.visited_nodes:
                    self.rewards[f"agent_{visited_node}"] += self.rewards_config['wrong_destination_penalty']
                continue

            # å°†æ•°æ®åŒ…æ·»åŠ åˆ°é€šé“ä¸­
            self.channels[node][next_node].append(packet)

        return packet_reached_destination

    def print_episode_summary(self):
        print("\n========== å›åˆç»“æŸï¼Œæ•°æ®åŒ…ä¼ è¾“ç»Ÿè®¡ ==========")
        print(f"æºèŠ‚ç‚¹: {self.source_node}, ç›®çš„èŠ‚ç‚¹: {self.destination_node}")
        print(f"æ€»æ•°æ®åŒ…æ•°: {len(self.current_episode_packets)}, æˆåŠŸä¼ è¾“æ•°: {self.received_packets_count}")

        # ç»Ÿè®¡ä¸¢åŒ…ä¿¡æ¯
        dropped_packets = [packet_id for packet_id in self.current_episode_packets
                           if self.all_packets[packet_id].is_dropped]
        print(f"ä¸¢å¼ƒæ•°æ®åŒ…æ•°: {len(dropped_packets)}")

        print("\næ•°æ®åŒ…ID | çŠ¶æ€ | è½¬å‘è·¯å¾„ | æ€»å»¶è¿Ÿ(ms)/åŸå› ")
        print("-" * 70)

        # ä¿®æ”¹æ’åºé€»è¾‘ï¼šæŒ‰ç…§æ•°å­—é¡ºåºæ’åº
        sorted_packets = sorted(self.current_episode_packets,
                                key=lambda x: int(x.replace('P', '')))

        for packet_id in sorted_packets:
            packet = self.all_packets[packet_id]
            path_str = ' -> '.join(map(str, packet.nodes))
            if packet.is_dropped:
                status = "ä¸¢å¼ƒ"
                info = f"åŸå› : {packet.drop_reason}"
            else:
                if packet.nodes[-1] == self.destination_node:
                    status = "æˆåŠŸ"
                    info = f"{packet.total_delay:6.2f}ms"
                else:
                    status = "æœªå®Œæˆ"
                    info = "æœªåˆ°è¾¾ç›®çš„èŠ‚ç‚¹"

            print(f"{packet_id:8} | {status:6} | {path_str:30} | {info}")

        print("=" * 70)

    def check_arrival_milestones(self):
        """æ£€æŸ¥å¹¶å¥–åŠ±åˆ°è¾¾ç‡é‡Œç¨‹ç¢‘"""
        if self.packets == 0:
            return False
            
        current_arrival_rate = self.received_packets_count / self.packets
        rewards_given = False
        
        for milestone, reward_key in sorted(self.arrival_milestones.items()):
            if milestone not in self.reached_arrival_milestones and current_arrival_rate >= milestone:
                self.reached_arrival_milestones.add(milestone)
                milestone_reward = self.rewards_config[reward_key]
                
                # ç»™æ‰€æœ‰æ™ºèƒ½ä½“å‘æ”¾é‡Œç¨‹ç¢‘å¥–åŠ±
                for agent_id in self.agents:
                    self.rewards[agent_id] += milestone_reward
                
                print(f"\nğŸ¯ åˆ°è¾¾ç‡è¾¾åˆ° {milestone*100}% é‡Œç¨‹ç¢‘ï¼æ‰€æœ‰æ™ºèƒ½ä½“è·å¾—å¥–åŠ±ï¼š{milestone_reward}")
                rewards_given = True
        
        return rewards_given
